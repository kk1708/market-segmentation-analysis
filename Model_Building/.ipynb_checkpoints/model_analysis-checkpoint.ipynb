{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sitting-advice",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "Based on our [observation of the dataset](model_selection.ipynb), we decided on using `KNN`, `Gradient Boosting` and `Random Forest` as our classification algorithms. Now it is time to test each model and measure their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protecting-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib as jb\n",
    "from model_generation import X_test, X_train, y_test, y_train\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "future-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the pre trained models\n",
    "gb = jb.load('models/GBC')\n",
    "rfc = jb.load('models/RFC')\n",
    "knn = jb.load('models/KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-deposit",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disabled-penny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4769230769230769"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best accuracy on the test set\n",
    "knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medium-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'ball_tree', 'n_neighbors': 30, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "solid-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performace of train data on the model \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.43      0.45      1342\n",
      "           1       0.41      0.29      0.34      1230\n",
      "           2       0.49      0.63      0.55      1347\n",
      "           3       0.63      0.68      0.65      1541\n",
      "\n",
      "    accuracy                           0.52      5460\n",
      "   macro avg       0.50      0.51      0.50      5460\n",
      "weighted avg       0.51      0.52      0.51      5460\n",
      "\n",
      "Performace of test data on the model \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.35      0.37       556\n",
      "           1       0.30      0.19      0.23       576\n",
      "           2       0.45      0.60      0.51       572\n",
      "           3       0.61      0.68      0.64       636\n",
      "\n",
      "    accuracy                           0.46      2340\n",
      "   macro avg       0.44      0.46      0.44      2340\n",
      "weighted avg       0.44      0.46      0.45      2340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating a classification report\n",
    "\n",
    "print(\"Performace of train data on the model \\n\",classification_report(y_train, knn.predict(X_train)))\n",
    "print(\"Performace of test data on the model \\n\",classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-bumper",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spoken-slave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5293040293040293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best accuracy on the test set\n",
    "rfc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "australian-central",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metropolitan-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performace of train data on the model \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58      1342\n",
      "           1       0.56      0.41      0.47      1230\n",
      "           2       0.62      0.63      0.63      1347\n",
      "           3       0.69      0.77      0.73      1541\n",
      "\n",
      "    accuracy                           0.62      5460\n",
      "   macro avg       0.61      0.61      0.60      5460\n",
      "weighted avg       0.61      0.62      0.61      5460\n",
      "\n",
      "Performace of test data on the model \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.49      0.46       556\n",
      "           1       0.44      0.30      0.36       576\n",
      "           2       0.57      0.61      0.59       572\n",
      "           3       0.66      0.74      0.70       636\n",
      "\n",
      "    accuracy                           0.54      2340\n",
      "   macro avg       0.53      0.54      0.53      2340\n",
      "weighted avg       0.53      0.54      0.53      2340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating a classification report\n",
    "\n",
    "print(\"Performace of train data on the model \\n\",classification_report(y_train, rfc.predict(X_train)))\n",
    "print(\"Performace of test data on the model \\n\",classification_report(y_test, rfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-active",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collected-aspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.530952380952381"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best accuracy on the test set\n",
    "gb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "julian-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best parameters\n",
    "gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "valued-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performace of train data on the model \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53      1342\n",
      "           1       0.50      0.43      0.46      1230\n",
      "           2       0.64      0.61      0.62      1347\n",
      "           3       0.67      0.77      0.71      1541\n",
      "\n",
      "    accuracy                           0.59      5460\n",
      "   macro avg       0.58      0.58      0.58      5460\n",
      "weighted avg       0.59      0.59      0.59      5460\n",
      "\n",
      "Performace of test data on the model \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.45      0.45       556\n",
      "           1       0.41      0.32      0.36       576\n",
      "           2       0.57      0.60      0.58       572\n",
      "           3       0.65      0.76      0.70       636\n",
      "\n",
      "    accuracy                           0.54      2340\n",
      "   macro avg       0.52      0.53      0.52      2340\n",
      "weighted avg       0.53      0.54      0.53      2340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating a classification report\n",
    "\n",
    "print(\"Performace of train data on the model \\n\",classification_report(y_train, gb.predict(X_train)))\n",
    "print(\"Performace of test data on the model \\n\",classification_report(y_test, gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-allah",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "By analysing the classification report, we observe that the `Gradient Boosting` algorithm gives us the **best score of 0.53%.** \n",
    "\n",
    "It is also noted that the `Performance of: 3` - those belonging to Segementation class 'D' - has the highest scores. This is because most of the elements in the training dataset were classified as 'D'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
